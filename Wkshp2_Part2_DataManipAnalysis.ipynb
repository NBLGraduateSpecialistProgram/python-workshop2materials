{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working with Pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we'll be using data from the UNHCR (UN Refugee Agency). The UNHCR has collected and published data on refugees, asylum seekers, and other \"populations of concern\" from 1951-2016; more information can be found at http://popstats.unhcr.org/en/overview."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## CODE CELL 1\n",
    "\n",
    "%matplotlib inline\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## CODE CELL 2\n",
    "# Reading in the first table\n",
    "\n",
    "persons = pd.read_csv('UN_refugee_data/unhcr_popstats_export_persons_of_concern_all_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the data frame to see what's going on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## CODE CELL 3\n",
    "# Showing top 5 rows\n",
    "\n",
    "persons.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## CODE CELL 4\n",
    "# Showing last 5 rows\n",
    "\n",
    "persons.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## CODE CELL 5\n",
    "# Let's get summary information\n",
    "\n",
    "persons.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we see two issues - one is that the header hasn't been assigned properly, and the other is that we have asterisks which we'd like to replace with NaN's (null values)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## CODE CELL 6\n",
    "# Re-read in the data\n",
    "\n",
    "persons = pd.read_csv('UN_refugee_data/unhcr_popstats_export_persons_of_concern_all_data.csv', header=3, na_values = '*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## CODE CELL 7\n",
    "# Checking if we resolved the issues\n",
    "\n",
    "persons.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## CODE CELL 8\n",
    "\n",
    "persons.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a lot of parameters you can adjust when reading in a CSV file; see the documentation for details: https://pandas.pydata.org/pandas-docs/stable/generated/pandas.read_csv.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some of the column names are long - let's replace them for convenience of analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## CODE CELL 9\n",
    "\n",
    "per_renamed = persons.rename(index=str, columns ={'Country / territory of asylum/residence': 'Residence',\n",
    "                                    'Refugees (incl. refugee-like situations)': 'Refugees',\n",
    "                                    'Asylum-seekers (pending cases)': 'Asylum-seekers',\n",
    "                                    'Internally displaced persons (IDPs)': 'IDPs'})\n",
    "per_renamed.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How do we look at specific columns?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## CODE CELL 10\n",
    "\n",
    "per_renamed['Origin']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many countries have refugees and asylum-seekers come from?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## CODE CELL 11\n",
    "# Count unique values in \"Origin\" column (we'll count \"Various/Unknown\" as one country)\n",
    "\n",
    "per_renamed['Origin'].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's say we want to focus on persons from Somalia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## CODE CELL 12\n",
    "\n",
    "somali = per_renamed[per_renamed['Origin'] == 'Somalia']\n",
    "somali"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's say we want to be more specific and focus on Somalis who have come to the U.S. between 2000-2016."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## CODE CELL 13\n",
    "\n",
    "somali_us = somali[(somali['Residence'] == 'United States of America') & (somali['Year'] >= 2000) & (somali['Year'] <= 2016)]\n",
    "somali_us"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can create a plot to look at the numeric data over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## CODE CELL 14\n",
    "# Selecting the population-data columns that do not have null values\n",
    "\n",
    "pops = somali_us.select_dtypes(include=['float'])\n",
    "pop_nonnull = pops.dropna(axis=1, how='any')\n",
    "pop_nonnull.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## CODE CELL 15\n",
    "# Plotting the time series (don't worry if a UserWarning appears due to passing a list of values to the y parameter;\n",
    "# this is a known issue in pandas and may be resolved in future versions of the library)\n",
    "\n",
    "pl = somali_us.plot(x='Year', y=pop_nonnull.columns)\n",
    "pl.set_ylabel('Persons')\n",
    "pl.set_title('Somali-to-U.S.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's go back to the larger data frame, per_renamed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## CODE CELL 16\n",
    "\n",
    "per_renamed.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You may have noticed the index on the leftmost side of the data frame. If we don't assign the index when we read in the data, pandas will automatically assign the row number as the index. But for faster and more convenient look-ups, you will often want to assign one of your columns as the index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## CODE CELL 17\n",
    "# Let's set \"Origin\" as our new index and sort the countries alphabetically\n",
    "\n",
    "origin_df = per_renamed.set_index('Origin').sort_index()\n",
    "origin_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is convenient, because now we can more quickly access certain rows and columns, like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## CODE CELL 18\n",
    "# Choosing rows corresponding to the slice between Somalia and Sudan (inclusive), and columns between Year and Asylum-seekers (inclusive)\n",
    "\n",
    "origin_df.loc['Somalia':'Sudan', 'Year':'Asylum-seekers']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you wanted to locate data by row/column numbers, you could use .iloc (integer-based location) instead of .loc (label-based location)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## CODE CELL 19\n",
    "\n",
    "origin_df.iloc[0, 0:4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, as we've alluded to previously, there are a lot of null values in this table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## CODE CELL 20\n",
    "# Quick way to check if there are any null values in each column\n",
    "\n",
    "pd.isnull(origin_df).any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## CODE CELL 21\n",
    "# Are there columns with ONLY null values?\n",
    "\n",
    "pd.isnull(origin_df).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## CODE CELL 22\n",
    "# Which rows have null values?\n",
    "\n",
    "origin_df[pd.isnull(origin_df).any(axis=1)].head(10)    # only want to look at the top 10 rows to save space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## CODE CELL 23\n",
    "# Which rows do NOT have null values?\n",
    "\n",
    "origin_df[pd.notnull(origin_df).all(axis=1)].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are several ways you might want to handle missing values, depending on your data and application. One way is to simply drop rows or columns with null values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## CODE CELL 24\n",
    "# Dropping rows with NaN's in \"Refugees\" or \"IDPs\" columns\n",
    "\n",
    "origin_df_nonnull = origin_df.dropna(axis=0, how='any', subset=['Refugees', 'IDPs'])\n",
    "origin_df_nonnull.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, sometimes dropping columns isn't feasible or desirable. You may instead want to impute missing values, replacing them with values that make sense in the context. \n",
    "\n",
    "Let's say we want to replace each NaN with the average value in its respective column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## CODE CELL 25\n",
    "# First, calculate the mean for each column (this may take a few seconds)\n",
    "\n",
    "means = origin_df.mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## CODE CELL 26\n",
    "\n",
    "means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## CODE CELL 27\n",
    "# Now, replace the NaN's\n",
    "\n",
    "origin_df.fillna(means).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively, you might want to replace null values with zeros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## CODE CELL 28\n",
    "\n",
    "origin_df.fillna(0).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at some operations we can do in pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## CODE CELL 29\n",
    "# Adding a new column representing the sum of \"Refugees\" and \"Returned refugees\" to per_renamed, the non-index-specified\n",
    "# dataframe (treating NaNs as zeros for the calculation)\n",
    "\n",
    "per_renamed['All refugees'] = per_renamed['Refugees'] + per_renamed['Returned refugees'].fillna(0)\n",
    "per_renamed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What if we want to look at the total number of refugees (not Returned) from each country in \"Origin\" by year? The easiest way to do this is by grouping the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## CODE CELL 30\n",
    "# Grouping data by Origin and Year, then calculating totals\n",
    "\n",
    "grouped_total = per_renamed.groupby(['Origin','Year'])['Refugees'].sum()\n",
    "grouped_total"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What if we want to find out which country \"produced\" (for lack of a better word) the most refugees, by year?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## CODE CELL 31\n",
    "# First, group and sum over each group\n",
    "\n",
    "grouped_new = per_renamed.groupby(['Year', 'Origin'])['Refugees'].sum()\n",
    "grouped_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## CODE CELL 32\n",
    "# We can use the DataFrame.unstack() method to pivot the years to columns\n",
    "\n",
    "unstacked = grouped_new.unstack(level=0)\n",
    "unstacked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## CODE CELL 33\n",
    "# Finally, use the DataFrame.idxmax() method to return the indices corresponding to the maximum value for each column\n",
    "\n",
    "max_origin = unstacked.idxmax(axis=0)\n",
    "max_origin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To visualize this, let's use the visualization library Seaborn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## CODE CELL 34\n",
    "\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## CODE CELL 35\n",
    "# Resetting \"Year\" to be a column for easier plotting, and renaming the country column label from the assigned \"0\" to Country\n",
    "\n",
    "max_origin_new = max_origin.reset_index()\n",
    "max_origin_df = max_origin_new.rename(index=str, columns={0: 'Country'})\n",
    "max_origin_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## CODE CELL 36\n",
    "# Swarm plot showing which country produced the most refugees by year\n",
    "\n",
    "sns.swarmplot(x='Year', y='Country', data=max_origin_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The last thing we'll look at is merging two tables together. Another table provided by the UNHCR is a table providing the number of resettlement arrivals for each Residence/Origin country pair between 1959-2016."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## CODE CELL 37\n",
    "# Reading in resettlement table\n",
    " \n",
    "resettle = pd.read_csv('UN_refugee_data/unhcr_popstats_export_resettlement_all_data.csv', header=3, na_values = '*')\n",
    "resettle.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How can we merge this data with the persons-of-concern data?\n",
    "\n",
    "First, let's rename the Residence column to match the naming convention in the per_renamed data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## CODE CELL 38\n",
    "# Also, rename \"Value\" to \"Resettled\"\n",
    "\n",
    "resettle_renamed = resettle.rename(index=str, columns ={'Country / territory of asylum/residence': 'Residence',\n",
    "                                                        'Value': 'Resettled'})\n",
    "resettle_renamed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## CODE CELL 39\n",
    "# Remember per_renamed?\n",
    "\n",
    "per_renamed.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It would make sense to merge on the combination of Year, Residence, and Origin. Also, since the resettlement data starts in 1959, we need to think about whether we want to keep the rows in per_renamed corresponding to the years between 1951 and 1959. If we want to keep all the data from the first dataframe regardless of whether there are corresponding rows with the same Year/Residence/Origin, we can specify `how='left'` in the merge (like a left join in SQL)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## CODE CELL 40\n",
    "# Let's say we want to keep the earlier data\n",
    "\n",
    "left_join = pd.merge(per_renamed, resettle_renamed, how='left', on = ['Year', 'Residence', 'Origin'])\n",
    "left_join[left_join['Residence'] == 'Canada']    # focusing on those who resettled in Canada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## CODE CELL 41\n",
    "# What if we only want to see the intersections of the two tables (where Year, Residence, and Origin all match up?)\n",
    "\n",
    "inner_join = pd.merge(per_renamed, resettle_renamed, how='inner', on = ['Year', 'Residence', 'Origin'])\n",
    "inner_join.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's output this last result to a new CSV file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## CODE CELL 42\n",
    "# Writing data to new file\n",
    "\n",
    "filename = 'UN_refugee_data/persons_resettlement_innerjoin.csv'\n",
    "inner_join.to_csv(filename, index=False)    # we don't want to print out the row number index that pandas assigned\n",
    "print('Check the UN_refugee_data folder for the new file.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 2:**\n",
    "\n",
    "A third table from UNHCR is a demographics table showing the gender and age breakdown on \"persons of concern\" in each region of a given residence country. Focusing on adults between the ages of 18-59 in the year 2016, determine the proportion of persons who are female in each country of residence, and find the countries which took in less than 25% female persons of concern in that year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## CODE CELL 43\n",
    "# Reading in demographics data\n",
    "\n",
    "demographics =  pd.read_csv('UN_refugee_data/unhcr_popstats_export_demographics_all_data.csv', header=3, na_values = '*')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer 2:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## CODE CELL 44\n",
    "\n",
    "## ENTER CODE HERE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are so many things you can do with pandas - we've just scratched the surface. The best way to learn it is really to get your hands dirty and start playing around with data. You may also want to check out the tutorials listed under *References*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*References*:\n",
    "\n",
    "The following materials were consulted during development of this notebook (the concept of calculating the proportion of female persons-of-concern in Assignment 2 was taken directly from Brandon Rhodes's tutorial):\n",
    "\n",
    "J. Gosset and A. Wright (eds), \"Data Carpentry Python Ecology lesson,\" Version 2017.04.0, April 2017, http://www.datacarpentry.org/python-ecology-lesson/.\n",
    "\n",
    "B. Rhodes, *PyCon Pandas Tutorial*, (2015), GitHub repository, https://github.com/brandon-rhodes/pycon-pandas-tutorial."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Data:*\n",
    "\n",
    "UNHCR Population Statistics Database, United Nations High Commissioner for Refugees (UNHCR), Data extracted: 21 March 2018.\n",
    "\n",
    "All refugee data used in this notebook comes from the UNHCR and can be found at http://popstats.unhcr.org under the Persons of Concern, Resettlement, and Demographics tabs, respectively. Data was exported following selection of appropriate checkboxes corresponding to the maximum amount of data output (e.g. \"All Years\" under the \"Years\" drop-down menu)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
