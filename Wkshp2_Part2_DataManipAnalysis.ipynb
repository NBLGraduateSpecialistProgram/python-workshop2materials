{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working with Pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we'll be using data from the UNHCR (UN Refugee Agency). The UNHCR has collected and published data on refugees, asylum seekers, and other \"populations of concern\" from 1951-2016; more information can be found at http://popstats.unhcr.org/en/overview."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading in the first table\n",
    "\n",
    "persons = pd.read_csv('UN_refugee_data/unhcr_popstats_export_persons_of_concern_all_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the data frame to see what's going on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Showing top 5 rows\n",
    "\n",
    "persons.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Showing last 5 rows\n",
    "\n",
    "persons.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's get summary information\n",
    "\n",
    "persons.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we see two issues - one is that the header hasn't been assigned properly, and the other is that we have asterisks which we'd like to replace with NaN's (null values)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Re-read in the data\n",
    "\n",
    "persons = pd.read_csv('UN_refugee_data/unhcr_popstats_export_persons_of_concern_all_data.csv', header=3, na_values = '*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking if we resolved the issues\n",
    "\n",
    "persons.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "persons.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a lot of parameters you can adjust when reading in a CSV file; see the documentation for details: https://pandas.pydata.org/pandas-docs/stable/generated/pandas.read_csv.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some of the column names are long - let's replace them for convenience of analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "per_renamed = persons.rename(index=str, columns ={'Country / territory of asylum/residence': 'Residence',\n",
    "                                    'Refugees (incl. refugee-like situations)': 'Refugees',\n",
    "                                    'Asylum-seekers (pending cases)': 'Asylum-seekers',\n",
    "                                    'Internally displaced persons (IDPs)': 'IDPs'})\n",
    "per_renamed.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How do we look at specific columns?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "per_renamed['Origin']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many countries have refugees and asylum-seekers come from?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count unique values in \"Residence\" column (we'll count \"Various/Unknown\" as one country)\n",
    "\n",
    "per_renamed['Origin'].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's say we want to focus on persons from Somalia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "somali = per_renamed[per_renamed['Origin'] == 'Somalia']\n",
    "somali"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's say we want to be more specific and focus on Somalis who have come to the U.S. between 2000-2016."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "somali_us = somali[(somali['Residence'] == 'United States of America') & (somali['Year'] >= 2000) & (somali['Year'] <= 2016)]\n",
    "somali_us"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can create a plot to look at the numeric data over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecting the population-data columns that do not have null values\n",
    "\n",
    "pops = somali_us.select_dtypes(include=['float'])\n",
    "pop_nonnull = pops.dropna(axis=1, how='any')\n",
    "pop_nonnull.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the time series\n",
    "\n",
    "pl = somali_us.plot(x='Year', y=pop_nonnull.columns)\n",
    "pl.set_ylabel('Persons')\n",
    "pl.set_title('Somali-to-U.S.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's go back to the larger data frame, per_renamed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "per_renamed.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You may have noticed the index on the leftmost side of the data frame. If we don't assign the index when we read in the data, pandas will automatically assign the row number as the index. But for faster and more convenient look-ups, you will often want to assign one of your columns as the index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's set \"Origin\" as our new index and sort the countries alphabetically\n",
    "\n",
    "origin_df = per_renamed.set_index('Origin').sort_index()\n",
    "origin_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is convenient, because now we can more quickly access certain rows and columns, like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choosing rows corresponding to the slice between Somalia and Sudan (inclusive), and the first four columns\n",
    "\n",
    "origin_df.loc['Somalia':'Sudan', 'Year':'Asylum-seekers']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you wanted to locate data by row/column numbers, you could use .iloc (integer-based location) instead of .loc (label-based location)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "origin_df.iloc[0, 0:4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, as we've alluded to previously, there are a lot of null values in this table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick way to check if there are any null values in each column\n",
    "\n",
    "pd.isnull(origin_df).any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Are there columns with ONLY null values?\n",
    "\n",
    "pd.isnull(origin_df).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Which rows have null values?\n",
    "\n",
    "origin_df[pd.isnull(origin_df).any(axis=1)].head(10)    # only want to look at the top 10 rows to save space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Which rows do NOT have null values?\n",
    "\n",
    "origin_df[pd.notnull(origin_df).all(axis=1)].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are several ways you might want to handle missing values, depending on your data and application. One way is to simply drop rows or columns with null values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping rows with NaN's in \"Refugees\" or \"IDPs\" columns\n",
    "\n",
    "origin_df_nonnull = origin_df.dropna(axis=0, how='any', subset=['Refugees', 'IDPs'])\n",
    "origin_df_nonnull.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, sometimes dropping columns isn't feasible or desirable. You may instead want to impute missing values, replacing them with values that make sense in the context. \n",
    "\n",
    "Let's say we want to replace each NaN with the average value in its respective column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# First, calculate the mean for each column (this will take ~ 15-20 seconds)\n",
    "\n",
    "means = origin_df.mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, replace the NaN's\n",
    "\n",
    "origin_df.fillna(means).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively, you might want to replace null values with zeros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "origin_df.fillna(0).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at some operations we can do in pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding a new column representing the sum of \"Refugees\" and \"Returned refugees\" to per_renamed, the non-index-specified\n",
    "# dataframe (treating NaNs as zeros for the calculation)\n",
    "\n",
    "per_renamed['All refugees'] = per_renamed['Refugees'] + per_renamed['Returned refugees'].fillna(0)\n",
    "per_renamed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What if we want to look at the total number of refugees (not Returned) from each country in \"Origin\" by year? The easiest way to do this is by grouping the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grouping data by Origin and Year, then calculating totals\n",
    "\n",
    "grouped_total = per_renamed.groupby(['Origin','Year'])['Refugees'].sum()\n",
    "grouped_total"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What if we want to find out which country \"produced\" (for lack of a better word) the most refugees, by year?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, group and sum over each group\n",
    "\n",
    "grouped_new = per_renamed.groupby(['Year', 'Origin'])['Refugees'].sum()\n",
    "grouped_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can use the DataFrame.unstack() method to pivot the years to columns\n",
    "\n",
    "unstacked = grouped_new.unstack(level=0)\n",
    "unstacked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finally, use the DataFrame.idxmax() method to return the indices corresponding to the maximum value for each column\n",
    "\n",
    "max_origin = unstacked.idxmax(axis=0)\n",
    "max_origin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To visualize this, let's use the visualization library Seaborn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resetting \"Year\" to be a column for easier plotting, and renaming the country column label from the assigned \"0\" to Country\n",
    "\n",
    "max_origin_new = max_origin.reset_index()\n",
    "max_origin_df = max_origin_new.rename(index=str, columns={0: 'Country'})\n",
    "max_origin_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Swarm plot showing which country produced the most refugees by year\n",
    "\n",
    "sns.swarmplot(x='Year', y='Country', data=max_origin_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The last thing we'll look at is merging two tables together. Another table provided by the UNHCR is a table providing the number of resettlement arrivals for each Residence/Origin country pair between 1959-2016."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading in resettlement table\n",
    " \n",
    "resettle = pd.read_csv('UN_refugee_data/unhcr_popstats_export_resettlement_all_data.csv', header=3, na_values = '*')\n",
    "resettle.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How can we merge this data with the persons-of-concern data?\n",
    "\n",
    "First, let's rename the Residence column to match the naming convention in the per_renamed data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Also, rename \"Value\" to \"Resettled\"\n",
    "\n",
    "resettle_renamed = resettle.rename(index=str, columns ={'Country / territory of asylum/residence': 'Residence',\n",
    "                                                        'Value': 'Resettled'})\n",
    "resettle_renamed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remember per_renamed?\n",
    "\n",
    "per_renamed.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It would make sense to merge on the combination of Year, Residence, and Origin. Also, since the resettlement data starts in 1959, we need to think about whether we want to keep the rows in per_renamed corresponding to the years between 1951 and 1959."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's say we want to keep the earlier data\n",
    "\n",
    "left_join = pd.merge(per_renamed, resettle_renamed, how='left', on = ['Year', 'Residence', 'Origin'])\n",
    "left_join[left_join['Residence'] == 'Canada']    # focusing on those who resettled in Canada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What if we only want to see the intersections of the two tables (where Year, Residence, and Origin all match up?)\n",
    "\n",
    "inner_join = pd.merge(per_renamed, resettle_renamed, how='inner', on = ['Year', 'Residence', 'Origin'])\n",
    "inner_join.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 2:**\n",
    "\n",
    "A third table from UNHCR is a demographics table showing the gender and age breakdown on \"persons of concern\" in each region of a given residence country. Focusing on adults between the ages of 18-59 in the year 2016, determine the proportion of persons who are female in each country of residence, and find the countries which took in less than 25% female persons of concern in that year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Reading in demographics data\n",
    "\n",
    "demographics =  pd.read_csv('UN_refugee_data/unhcr_popstats_export_demographics_all_data.csv', header=3, na_values = '*')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer 2:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## ENTER CODE HERE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are so many things you can do with pandas - we've just scratched the surface. The best way to learn it is really to get your hands dirty and start playing around with data. You may also want to check out the tutorials listed under *References*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*References*:\n",
    "\n",
    "The following materials were consulted during development of this notebook (the concept of calculating the proportion of female persons-of-concern in Assignment 2 was taken directly from Brandon Rhodes's tutorial):\n",
    "\n",
    "John Gosset, April Wright (eds): \"Data Carpentry Python Ecology lesson.\" Version 2017.04.0, April 2017, http://www.datacarpentry.org/python-ecology-lesson/.\n",
    "\n",
    "Brandon Rhodes, PyCon 2015 Pandas Tutorial Materials, 2015, GitHub repository, https://github.com/brandon-rhodes/pycon-pandas-tutorial."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Data:*\n",
    "\n",
    "All refugee data used in this notebook comes from the UNHCR and can be found at http://popstats.unhcr.org under the Persons of Concern, Resettlement, and Demographics tabs, respectively. Data was exported following selection of appropriate checkboxes corresponding to the maximum amount of data output (e.g. \"All Years\" under the \"Years\" drop-down menu)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
